from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from typing import List
from app import crud, schemas, database, services
from fastapi import File, UploadFile, BackgroundTasks
from fastapi import Form
from datetime import datetime
from fastapi.responses import FileResponse
from pydantic import BaseModel
import pandas as pd
import os

class ChatRequest(BaseModel):
    question: str

class CustomerAnalyzeRequest(BaseModel):
    name: str

router = APIRouter()

@router.get("/feedbacks", response_model=List[schemas.FeedbackResponse])
def read_feedbacks(skip: int = 0, limit: int = 20, db: Session = Depends(database.get_db)):
    return crud.get_feedbacks(db, skip, limit)

@router.get("/dashboard/stats", response_model=schemas.DashboardStats)
def read_stats(db: Session = Depends(database.get_db)):
    return crud.get_stats(db)

# API test nh·∫≠p d·ªØ li·ªáu nhanh
@router.post("/feedbacks/test-create")
def test_create_feedback(content: str, db: Session = Depends(database.get_db)):
    return crud.create_feedback_with_analysis(db, content)

@router.post("/feedbacks/upload-csv")
async def upload_csv(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    platform: str = Form(...),
    db: Session = Depends(database.get_db)
):
    contents = await file.read()
    # Truy·ªÅn platform v√†o h√†m x·ª≠ l√Ω
    background_tasks.add_task(crud.process_csv_upload, db, contents, platform)
    
    return {
        "message": f"ƒêang x·ª≠ l√Ω file {platform}...",
        "filename": file.filename
    }

@router.get("/dashboard/keywords")
def read_keywords(db: Session = Depends(database.get_db)):
    return crud.get_keyword_stats(db)

@router.put("/feedbacks/{feedback_id}/analysis")
def update_feedback_analysis(
    feedback_id: str, 
    payload: schemas.AnalysisUpdate, 
    db: Session = Depends(database.get_db)
):
    result = crud.update_analysis_result(db, feedback_id, payload.sentiment_label)
    if not result:
        raise HTTPException(status_code=404, detail="Kh√¥ng t√¨m th·∫•y Feedback")
    return {"message": "C·∫≠p nh·∫≠t th√†nh c√¥ng", "data": result}

@router.get("/feedbacks/export")
def export_feedbacks(db: Session = Depends(database.get_db)):
    # 1. L·∫•y d·ªØ li·ªáu t·ª´ DB (k√®m k·∫øt qu·∫£ ph√¢n t√≠ch)
    feedbacks = crud.get_feedbacks(db, limit=10000) # L·∫•y t·ªëi ƒëa 10k d√≤ng
    
    # 2. Chuy·ªÉn ƒë·ªïi sang list dict ƒë·ªÉ ƒë∆∞a v√†o Pandas
    data = []
    for f in feedbacks:
        # Flatten d·ªØ li·ªáu (l√†m ph·∫≥ng)
        item = {
            "ID": str(f.id),
            "Ngu·ªìn": f.customer_info.get("imported_from"),
            "Th·ªùi gian": f.customer_info.get("time_posted"),
            "N·ªôi dung g·ªëc": f.raw_content,
            "Ng∆∞·ªùi g·ª≠i": f.customer_info.get("name") if f.customer_info else "",
            "Likes": f.customer_info.get("likes") if f.customer_info else 0,
            "C·∫£m x√∫c (AI)": f.analysis.sentiment_label if f.analysis else "N/A",
            "ƒêi·ªÉm s·ªë": f.analysis.sentiment_score if f.analysis else 0,
            "T·ª´ kh√≥a": ", ".join(f.analysis.keywords) if f.analysis and f.analysis.keywords else ""
        }
        data.append(item)
    
    # 3. T·∫°o DataFrame
    df = pd.DataFrame(data)
    
    # 4. Ghi ra file Excel t·∫°m
    filename = f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
    filepath = os.path.join("tmp", filename) # L∆∞u v√†o th∆∞ m·ª•c tmp trong backend
    
    # D√πng engine openpyxl ƒë·ªÉ ghi
    df.to_excel(filepath, index=False, engine='openpyxl')
    
    # 5. Tr·∫£ v·ªÅ file cho tr√¨nh duy·ªát t·∫£i xu·ªëng
    return FileResponse(
        path=filepath, 
        filename=filename, 
        media_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
    )

@router.post("/chat/ask")
def chat_with_data(payload: ChatRequest, db: Session = Depends(database.get_db)):
    # 1. L·∫•y d·ªØ li·ªáu m·ªõi nh·∫•t t·ª´ DB ƒë·ªÉ l√†m ng·ªØ c·∫£nh
    # L·∫•y 50 comment m·ªõi nh·∫•t (Gemini Flash x·ª≠ l√Ω ƒë∆∞·ª£c c·∫£ ng√†n comment, nh∆∞ng test 50 cho nhanh)
    recent_feedbacks = crud.get_feedbacks(db, limit=20)
    
    # 2. Ch·∫ø bi·∫øn d·ªØ li·ªáu g·ªçn nh·∫π ƒë·ªÉ ti·∫øt ki·ªám token
    context_data = []
    for f in recent_feedbacks:
        context_data.append({
            "content": f.raw_content,
            "label": f.analysis.sentiment_label if f.analysis else "Unknown"
        })
    
    # 3. G·ªçi service h·ªèi Gemini
    answer = services.ask_gemini_about_data(payload.question, context_data)
    
    return {"answer": answer}

@router.get("/customers", response_model=schemas.PaginatedCustomerResponse)
def read_customers(page: int = 1, per_page: int = 10, db: Session = Depends(database.get_db)):
    skip = (page - 1) * per_page
    customers, total_count = crud.get_customer_profiles(db, skip=skip, limit=per_page)
    total_pages = (total_count + per_page - 1) // per_page  # Ceiling division

    return {
        "customers": customers,
        "total_count": total_count,
        "total_pages": total_pages,
        "current_page": page,
        "per_page": per_page
    }

@router.post("/customers/analyze-profile")
def analyze_customer(payload: CustomerAnalyzeRequest, db: Session = Depends(database.get_db)):
    # 1. L·∫•y l·ªãch s·ª≠
    history = crud.get_customer_history(db, payload.name)
    
    # 2. G·ªçi AI ph√¢n t√≠ch
    insight = services.analyze_customer_persona(payload.name, history)
    
    return {
        "customer": payload.name,
        "history_count": len(history),
        "insight": insight
    }

@router.post("/feedbacks/batch-import")
def batch_import_feedbacks(
    payload: schemas.ScrapeBatchRequest, 
    background_tasks: BackgroundTasks, # X·ª≠ l√Ω ng·∫ßm cho nhanh
    db: Session = Depends(database.get_db)
):
    print(f"üì° Nh·∫≠n {len(payload.items)} comment t·ª´ Extension. URL: {payload.url}")
    
    # Ch√∫ng ta t√°i s·ª≠ d·ª•ng logic x·ª≠ l√Ω ng·∫ßm gi·ªëng nh∆∞ CSV
    # Nh∆∞ng l·∫ßn n√†y kh√¥ng c·∫ßn ƒë·ªçc file, m√† loop qua list items lu√¥n
    
    # ƒê·ªãnh nghƒ©a h√†m x·ª≠ l√Ω con (ho·∫∑c chuy·ªÉn v√†o crud.py n·∫øu mu·ªën s·∫°ch code)
    def process_batch_items(items, source_platform):
        count = 0
        # X√°c ƒë·ªãnh Source ID
        src_id = 3 # Other
        if source_platform == 'FACEBOOK': src_id = 1
        elif source_platform == 'SHOPEE': src_id = 2
            
        for item in items:
            try:
                # 1. T·∫°o Feedback
                # L∆∞u √Ω: H√†m create_feedback_with_analysis c·∫ßn import t·ª´ crud
                db_feedback = crud.create_feedback_with_analysis(db, item.content, source_id=src_id)
                
                # 2. Update Metadata
                db_feedback.customer_info = {
                    "name": item.author_name,
                    "likes": str(item.likes),
                    "imported_from": "chrome_extension",
                    "original_url": payload.url
                }
                db.commit()
                count += 1
            except Exception as e:
                print(f"L·ªói d√≤ng: {e}")
                continue
        print(f"‚úÖ ƒê√£ import th√†nh c√¥ng {count} d√≤ng t·ª´ Extension.")

    # ƒê·∫©y v√†o background tasks
    background_tasks.add_task(process_batch_items, payload.items, payload.items[0].source_platform if payload.items else "OTHER")

    return {"message": "ƒê√£ nh·∫≠n d·ªØ li·ªáu, ƒëang x·ª≠ l√Ω ng·∫ßm...", "count": len(payload.items)}