from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from typing import List
from app import crud, schemas, database, services
from fastapi import File, UploadFile, BackgroundTasks
from fastapi import Form
from datetime import datetime
from fastapi.responses import FileResponse
from pydantic import BaseModel
from dateutil import parser
import pandas as pd
import os

class ChatRequest(BaseModel):
    question: str

class CustomerAnalyzeRequest(BaseModel):
    name: str

router = APIRouter()

@router.get("/feedbacks", response_model=List[schemas.FeedbackResponse])
def read_feedbacks(skip: int = 0, limit: int = 20, db: Session = Depends(database.get_db)):
    return crud.get_feedbacks(db, skip, limit)

@router.get("/dashboard/stats", response_model=schemas.DashboardStats)
def read_stats(db: Session = Depends(database.get_db)):
    return crud.get_stats(db)

# API test nh·∫≠p d·ªØ li·ªáu nhanh
@router.post("/feedbacks/test-create")
def test_create_feedback(content: str, db: Session = Depends(database.get_db)):
    return crud.create_feedback_with_analysis(db, content)

@router.post("/feedbacks/upload-csv")
async def upload_csv(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    platform: str = Form(...),
    db: Session = Depends(database.get_db)
):
    contents = await file.read()
    # Truy·ªÅn platform v√†o h√†m x·ª≠ l√Ω
    background_tasks.add_task(crud.process_csv_upload, db, contents, platform)
    
    return {
        "message": f"ƒêang x·ª≠ l√Ω file {platform}...",
        "filename": file.filename
    }

@router.get("/dashboard/keywords")
def read_keywords(db: Session = Depends(database.get_db)):
    return crud.get_keyword_stats(db)

@router.put("/feedbacks/{feedback_id}/analysis")
def update_feedback_analysis(
    feedback_id: str, 
    payload: schemas.AnalysisUpdate, 
    db: Session = Depends(database.get_db)
):
    result = crud.update_analysis_result(db, feedback_id, payload.sentiment_label)
    if not result:
        raise HTTPException(status_code=404, detail="Kh√¥ng t√¨m th·∫•y Feedback")
    return {"message": "C·∫≠p nh·∫≠t th√†nh c√¥ng", "data": result}

@router.get("/feedbacks/export")
def export_feedbacks(db: Session = Depends(database.get_db)):
    # 1. L·∫•y d·ªØ li·ªáu t·ª´ DB (k√®m k·∫øt qu·∫£ ph√¢n t√≠ch)
    feedbacks = crud.get_feedbacks(db, limit=10000) # L·∫•y t·ªëi ƒëa 10k d√≤ng
    
    # 2. Chuy·ªÉn ƒë·ªïi sang list dict ƒë·ªÉ ƒë∆∞a v√†o Pandas
    data = []
    for f in feedbacks:
        # Flatten d·ªØ li·ªáu (l√†m ph·∫≥ng)
        item = {
            "ID": str(f.id),
            "Ngu·ªìn": f.customer_info.get("imported_from"),
            "Th·ªùi gian": f.customer_info.get("time_posted"),
            "N·ªôi dung g·ªëc": f.raw_content,
            "Ng∆∞·ªùi g·ª≠i": f.customer_info.get("name") if f.customer_info else "",
            "Likes": f.customer_info.get("likes") if f.customer_info else 0,
            "C·∫£m x√∫c (AI)": f.analysis.sentiment_label if f.analysis else "N/A",
            "ƒêi·ªÉm s·ªë": f.analysis.sentiment_score if f.analysis else 0,
            "T·ª´ kh√≥a": ", ".join(f.analysis.keywords) if f.analysis and f.analysis.keywords else ""
        }
        data.append(item)
    
    # 3. T·∫°o DataFrame
    df = pd.DataFrame(data)
    
    # 4. Ghi ra file Excel t·∫°m
    filename = f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
    filepath = os.path.join("tmp", filename) # L∆∞u v√†o th∆∞ m·ª•c tmp trong backend
    
    # D√πng engine openpyxl ƒë·ªÉ ghi
    df.to_excel(filepath, index=False, engine='openpyxl')
    
    # 5. Tr·∫£ v·ªÅ file cho tr√¨nh duy·ªát t·∫£i xu·ªëng
    return FileResponse(
        path=filepath, 
        filename=filename, 
        media_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
    )

@router.post("/chat/ask")
def chat_with_data(payload: ChatRequest, db: Session = Depends(database.get_db)):
    # 1. L·∫•y d·ªØ li·ªáu m·ªõi nh·∫•t t·ª´ DB ƒë·ªÉ l√†m ng·ªØ c·∫£nh
    # L·∫•y 50 comment m·ªõi nh·∫•t (Gemini Flash x·ª≠ l√Ω ƒë∆∞·ª£c c·∫£ ng√†n comment, nh∆∞ng test 50 cho nhanh)
    recent_feedbacks = crud.get_feedbacks(db, limit=20)
    
    # 2. Ch·∫ø bi·∫øn d·ªØ li·ªáu g·ªçn nh·∫π ƒë·ªÉ ti·∫øt ki·ªám token
    context_data = []
    for f in recent_feedbacks:
        context_data.append({
            "content": f.raw_content,
            "label": f.analysis.sentiment_label if f.analysis else "Unknown"
        })
    
    # 3. G·ªçi service h·ªèi Gemini
    answer = services.ask_gemini_about_data(payload.question, context_data)
    
    return {"answer": answer}

@router.get("/customers", response_model=schemas.PaginatedCustomerResponse)
def read_customers(page: int = 1, per_page: int = 10, db: Session = Depends(database.get_db)):
    skip = (page - 1) * per_page
    customers, total_count = crud.get_customer_profiles(db, skip=skip, limit=per_page)
    total_pages = (total_count + per_page - 1) // per_page  # Ceiling division

    return {
        "customers": customers,
        "total_count": total_count,
        "total_pages": total_pages,
        "current_page": page,
        "per_page": per_page
    }

@router.post("/customers/analyze-profile")
def analyze_customer(payload: CustomerAnalyzeRequest, db: Session = Depends(database.get_db)):
    # 1. L·∫•y l·ªãch s·ª≠
    history = crud.get_customer_history(db, payload.name)
    
    # 2. G·ªçi AI ph√¢n t√≠ch
    insight = services.analyze_customer_persona(payload.name, history)
    
    return {
        "customer": payload.name,
        "history_count": len(history),
        "insight": insight
    }

@router.post("/feedbacks/batch-import")
def batch_import_feedbacks(
    payload: schemas.ScrapeBatchRequest, 
    background_tasks: BackgroundTasks,
    db: Session = Depends(database.get_db)
):
    print(f"üì° Nh·∫≠n {len(payload.items)} comment t·ª´ Extension. URL: {payload.url}")
    
    def process_batch_items(items, source_platform):
        count = 0
        src_id = 3
        if source_platform == 'FACEBOOK': src_id = 1
        elif source_platform == 'SHOPEE': src_id = 2
            
        for item in items:
            try:
                # 1. X·ª¨ L√ù TH·ªúI GIAN
                real_time = None
                if item.created_at:
                    try:
                        # Extension g·ª≠i l√™n d·∫°ng chu·ªói ISO (2025-12-23T...)
                        # Ta convert sang object datetime c·ªßa Python
                        real_time = parser.parse(item.created_at)
                    except:
                        print(f"‚ö†Ô∏è Kh√¥ng parse ƒë∆∞·ª£c ng√†y: {item.created_at}")
                        real_time = None

                # 2. G·ªåI CRUD V·ªöI TH·ªúI GIAN TH·ª∞C
                # Truy·ªÅn real_time v√†o ƒë√¢y ƒë·ªÉ n√≥ l∆∞u v√†o c·ªôt received_at
                db_feedback = crud.create_feedback_with_analysis(
                    db, 
                    item.content, 
                    source_id=src_id, 
                    custom_time=real_time
                )
                
                # 3. Update Metadata (C√°c th√¥ng tin ph·ª•)
                db_feedback.customer_info = {
                    "name": item.author_name,
                    "likes": str(item.likes),
                    "imported_from": "chrome_extension",
                    "original_url": payload.url,
                    "original_timestamp": item.created_at # L∆∞u th√™m v√†o ƒë√¢y ƒë·ªÉ backup
                }
                db.commit()
                count += 1
            except Exception as e:
                print(f"L·ªói d√≤ng: {e}")
                continue
        print(f"‚úÖ ƒê√£ import th√†nh c√¥ng {count} d√≤ng.")

    background_tasks.add_task(process_batch_items, payload.items, payload.items[0].source_platform if payload.items else "OTHER")
    return {"message": "ƒêang x·ª≠ l√Ω...", "count": len(payload.items)}

@router.get("/dashboard/trend")
def get_trend(days: int = 1, db: Session = Depends(database.get_db)):
    return crud.get_sentiment_trend(db, days)