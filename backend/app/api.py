from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from typing import List
from app import crud, schemas, database, services, models
from fastapi import File, UploadFile, BackgroundTasks
from fastapi import Form
from datetime import datetime
from fastapi.responses import FileResponse
from pydantic import BaseModel
from dateutil import parser
import pandas as pd
import os

class ChatRequest(BaseModel):
    question: str

class CustomerAnalyzeRequest(BaseModel):
    name: str

class MonitorRequest(BaseModel):
    url: str
    platform: str

router = APIRouter()

@router.get("/feedbacks", response_model=List[schemas.FeedbackResponse])
def read_feedbacks(skip: int = 0, limit: int = 10, db: Session = Depends(database.get_db)):
    return crud.get_feedbacks(db, skip, limit)

@router.get("/dashboard/stats", response_model=schemas.DashboardStats)
def read_stats(db: Session = Depends(database.get_db)):
    return crud.get_stats(db)

# API test nh·∫≠p d·ªØ li·ªáu nhanh
@router.post("/feedbacks/test-create")
def test_create_feedback(content: str, db: Session = Depends(database.get_db)):
    return crud.create_feedback_with_analysis(db, content)

@router.post("/feedbacks/upload-csv")
async def upload_csv(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    platform: str = Form(...),
    db: Session = Depends(database.get_db)
):
    contents = await file.read()
    # Truy·ªÅn platform v√†o h√†m x·ª≠ l√Ω
    background_tasks.add_task(crud.process_csv_upload, db, contents, platform)
    
    return {
        "message": f"ƒêang x·ª≠ l√Ω file {platform}...",
        "filename": file.filename
    }

@router.get("/dashboard/keywords")
def read_keywords(db: Session = Depends(database.get_db)):
    return crud.get_keyword_stats(db)

@router.put("/feedbacks/{feedback_id}/analysis")
def update_feedback_analysis(
    feedback_id: str, 
    payload: schemas.AnalysisUpdate, 
    db: Session = Depends(database.get_db)
):
    result = crud.update_analysis_result(db, feedback_id, payload.sentiment_label)
    if not result:
        raise HTTPException(status_code=404, detail="Kh√¥ng t√¨m th·∫•y Feedback")
    return {"message": "C·∫≠p nh·∫≠t th√†nh c√¥ng", "data": result}

@router.get("/feedbacks/export")
def export_feedbacks(db: Session = Depends(database.get_db)):
    # 0. L·∫•y danh s√°ch ngu·ªìn ƒë√£ c·∫•u h√¨nh
    sources = db.query(models.Source).all()
    source_map = {s.id: s.name for s in sources}

    # 1. L·∫•y d·ªØ li·ªáu t·ª´ DB (k√®m k·∫øt qu·∫£ ph√¢n t√≠ch)
    feedbacks = crud.get_feedbacks(db, limit=1000) # L·∫•y t·ªëi ƒëa 10k d√≤ng
    
    # 2. Chuy·ªÉn ƒë·ªïi sang list dict ƒë·ªÉ ƒë∆∞a v√†o Pandas
    data = []
    for f in feedbacks:
        # X·ª≠ l√Ω Logic Ngu·ªìn
        source_name = f.customer_info.get("imported_from") if f.customer_info else "Unknown"
        
        # N·∫øu c√≥ source_id h·ª£p l·ªá (1, 2, 3) th√¨ l·∫•y t√™n c·∫•u h√¨nh
        if f.source_id and f.source_id in source_map and f.source_id in [1, 2, 3]:
            source_name = source_map[f.source_id]

        # Flatten d·ªØ li·ªáu (l√†m ph·∫≥ng)
        item = {
            "ID": str(f.id),
            "Ngu·ªìn": source_name,
            "Th·ªùi gian": f.customer_info.get("original_timestamp") if f.customer_info else "",
            "N·ªôi dung g·ªëc": f.raw_content,
            "Ng∆∞·ªùi g·ª≠i": f.customer_info.get("name") if f.customer_info else "",
            "Likes": f.customer_info.get("likes") if f.customer_info else 0,
            "C·∫£m x√∫c (AI)": f.analysis.sentiment_label if f.analysis else "N/A",
            "ƒêi·ªÉm s·ªë": f.analysis.sentiment_score if f.analysis else 0,
            "T·ª´ kh√≥a": ", ".join(f.analysis.keywords) if f.analysis and f.analysis.keywords else ""
        }
        data.append(item)
    
    # 3. T·∫°o DataFrame
    df = pd.DataFrame(data)
    
    # 4. Ghi ra file Excel t·∫°m
    filename = f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
    filepath = os.path.join("tmp", filename) # L∆∞u v√†o th∆∞ m·ª•c tmp trong backend
    
    # D√πng engine openpyxl ƒë·ªÉ ghi
    os.makedirs("tmp", exist_ok=True) # Ensure tmp dir exists
    df.to_excel(filepath, index=False, engine='openpyxl')
    
    # 5. Tr·∫£ v·ªÅ file cho tr√¨nh duy·ªát t·∫£i xu·ªëng
    return FileResponse(
        path=filepath, 
        filename=filename, 
        media_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
    )

@router.post("/chat/ask")
def chat_with_data(payload: ChatRequest, db: Session = Depends(database.get_db)):
    # 1. L·∫•y d·ªØ li·ªáu m·ªõi nh·∫•t t·ª´ DB ƒë·ªÉ l√†m ng·ªØ c·∫£nh
    # L·∫•y 50 comment m·ªõi nh·∫•t (Gemini Flash x·ª≠ l√Ω ƒë∆∞·ª£c c·∫£ ng√†n comment, nh∆∞ng test 50 cho nhanh)
    recent_feedbacks = crud.get_feedbacks(db, limit=20)
    
    # 2. Ch·∫ø bi·∫øn d·ªØ li·ªáu g·ªçn nh·∫π ƒë·ªÉ ti·∫øt ki·ªám token
    context_data = []
    for f in recent_feedbacks:
        context_data.append({
            "content": f.raw_content,
            "label": f.analysis.sentiment_label if f.analysis else "Unknown"
        })
    
    # 3. G·ªçi service h·ªèi Gemini
    answer = services.ask_gemini_about_data(payload.question, context_data)
    
    return {"answer": answer}

@router.get("/customers", response_model=schemas.PaginatedCustomerResponse)
def read_customers(page: int = 1, per_page: int = 10, db: Session = Depends(database.get_db)):
    skip = (page - 1) * per_page
    customers, total_count = crud.get_customer_profiles(db, skip=skip, limit=per_page)
    total_pages = (total_count + per_page - 1) // per_page  # Ceiling division

    return {
        "customers": customers,
        "total_count": total_count,
        "total_pages": total_pages,
        "current_page": page,
        "per_page": per_page
    }

@router.post("/customers/analyze-profile")
def analyze_customer(payload: CustomerAnalyzeRequest, db: Session = Depends(database.get_db)):
    # 1. L·∫•y l·ªãch s·ª≠
    history = crud.get_customer_history(db, payload.name)
    
    # 2. G·ªçi AI ph√¢n t√≠ch
    insight = services.analyze_customer_persona(payload.name, history)
    
    return {
        "customer": payload.name,
        "history_count": len(history),
        "insight": insight
    }

@router.post("/feedbacks/batch-import")
def batch_import_feedbacks(
    payload: schemas.ScrapeBatchRequest, 
    background_tasks: BackgroundTasks,
    db: Session = Depends(database.get_db)
):
    print(f"üì° Nh·∫≠n {len(payload.items)} comment t·ª´ Extension. URL: {payload.url}")
    
    def process_batch_items(items, source_platform):
        count = 0
        src_id = 3
        if source_platform == 'FACEBOOK': src_id = 1
        elif source_platform == 'SHOPEE': src_id = 2
            
        for item in items:
            try:
                # 1. X·ª¨ L√ù TH·ªúI GIAN (∆Øu ti√™n original_timestamp n·∫øu c√≥)
                final_time = None
                
                # Logic parse th·ªùi gian an to√†n
                time_str_to_parse = item.original_timestamp or item.created_at
                if time_str_to_parse:
                    try:
                        final_time = parser.parse(time_str_to_parse)
                    except:
                        final_time = datetime.now() # Fallback n·∫øu l·ªói format

                # 2. G·ªåI CRUD
                # L∆∞u √Ω: Pass final_time v√†o ƒë·ªÉ DB l∆∞u ƒë√∫ng ng√†y kh√°ch comment
                db_feedback = crud.create_feedback_with_analysis(
                    db, 
                    item.content, 
                    source_id=src_id, 
                    custom_time=final_time 
                )
                
                # 3. CHU·∫®N B·ªä JSON CUSTOMER INFO
                info_data = {
                    "name": item.author_name,
                    "likes": str(item.likes),
                    "imported_from": "chrome_extension",
                    "original_url": payload.url,
                    "original_timestamp": item.original_timestamp 
                }

                # 4. G√ÅN V√ÄO DB V√ÄO √âP KI·ªÇU DICT
                # SQLAlchemy c·∫ßn g√°n ƒë√® l·∫°i ƒë·ªÉ nh·∫≠n bi·∫øt thay ƒë·ªïi v·ªõi JSON
                db_feedback.customer_info = info_data
                
                db.add(db_feedback) 
                db.commit()
                count += 1
            except Exception as e:
                print(f"‚ùå L·ªói d√≤ng: {e}")
                db.rollback()
                continue
        print(f"‚úÖ ƒê√£ import th√†nh c√¥ng {count} d√≤ng.")

    background_tasks.add_task(process_batch_items, payload.items, payload.items[0].source_platform if payload.items else "OTHER")
    return {"message": "ƒêang x·ª≠ l√Ω...", "count": len(payload.items)}

@router.get("/dashboard/trend")
def get_trend(days: int = 1, db: Session = Depends(database.get_db)):
    return crud.get_sentiment_trend(db, days)

@router.post("/monitor", response_model=schemas.MonitorTaskResponse)
def add_monitor_task(payload: schemas.MonitorTaskCreate, db: Session = Depends(database.get_db)):
    # Ki·ªÉm tra tr√πng l·∫∑p
    exists = db.query(models.MonitorTask).filter(models.MonitorTask.url == payload.url).first()
    if exists:
        # N·∫øu ƒë√£ c√≥ th√¨ k√≠ch ho·∫°t l·∫°i
        exists.is_active = True
        db.commit()
        db.refresh(exists)
        return exists

    new_task = models.MonitorTask(
        url=payload.url,
        memo=payload.memo,
        platform=payload.platform,
        is_active=True
    )
    db.add(new_task)
    db.commit()
    db.refresh(new_task)
    return new_task

@router.get("/monitor", response_model=List[schemas.MonitorTaskResponse])
def get_monitor_tasks(db: Session = Depends(database.get_db)):
    # Ch·ªâ l·∫•y c√°c task ƒëang k√≠ch ho·∫°t ƒë·ªÉ Extension ch·∫°y
    return db.query(models.MonitorTask).filter(models.MonitorTask.is_active == True).all()

@router.delete("/monitor/{task_id}")
def delete_monitor_task(task_id: int, db: Session = Depends(database.get_db)):
    task = db.query(models.MonitorTask).filter(models.MonitorTask.id == task_id).first()
    if task:
        # X√≥a m·ªÅm (ch·ªâ t·∫Øt active) ho·∫∑c x√≥a c·ª©ng t√πy b·∫°n. ·ªû ƒë√¢y ta x√≥a c·ª©ng cho g·ªçn.
        db.delete(task)
        db.commit()
    return {"message": "ƒê√£ x√≥a task"}